{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 300 - Convolution network, gradient, tweaks, with pytorch\n",
        "\n",
        "Object detection on [CIFAR10](https://www.kaggle.com/c/cifar-10)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** install [tqdm](https://pypi.python.org/pypi/tqdm) if not installed: ``!pip install tqdm``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch 0.2.0_4\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "print(\"torch\", torch.__version__)\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "DATA_DIR = '/home/xd_ensae/data/'\n",
        "USE_CUDA = True\n",
        "N_EPOCHS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(DATA_DIR, train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10(DATA_DIR, train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=TEST_BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(500, 50)\n",
        "        self.fc2 = nn.Linear(50, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 500)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "if USE_CUDA: model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(epoch, verbose=True):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    loader = tqdm(train_loader, total=len(train_loader))\n",
        "    for batch_idx, (data, target) in enumerate(loader):\n",
        "        if USE_CUDA:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(float(loss.data[0]))\n",
        "        if verbose and batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
        "    return np.mean(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def test(verbose=True):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if USE_CUDA: data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data, volatile=True), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    if verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            test_loss, correct, len(test_loader.dataset),\n",
        "            100. * correct / len(test_loader.dataset)))\n",
        "    return [float(test_loss), correct]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 74.27it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1: train loss 2.1699, test loss 1.7524, accuracy 3675/10000 in 12.01s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.76it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2: train loss 1.8401, test loss 1.6206, accuracy 4170/10000 in 11.40s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.53it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 73.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3: train loss 1.7630, test loss 1.5700, accuracy 4266/10000 in 11.57s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 75.87it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4: train loss 1.7248, test loss 1.5173, accuracy 4500/10000 in 11.88s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.68it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.96it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5: train loss 1.6856, test loss 1.5035, accuracy 4717/10000 in 11.28s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.23it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6: train loss 1.6623, test loss 1.4833, accuracy 4761/10000 in 11.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.71it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7: train loss 1.6410, test loss 1.4474, accuracy 4833/10000 in 11.40s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.05it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8: train loss 1.6247, test loss 1.4428, accuracy 4869/10000 in 11.57s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.19it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 72.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9: train loss 1.6130, test loss 1.3940, accuracy 4994/10000 in 11.68s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.85it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 74.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 10: train loss 1.6038, test loss 1.3807, accuracy 5107/10000 in 11.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.45it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 11: train loss 1.5972, test loss 1.3783, accuracy 5171/10000 in 11.56s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.16it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 75.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 12: train loss 1.5815, test loss 1.3714, accuracy 5168/10000 in 11.54s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 75.56it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 79.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 13: train loss 1.5705, test loss 1.3465, accuracy 5320/10000 in 11.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.23it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 81.09it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 14: train loss 1.5621, test loss 1.3515, accuracy 5294/10000 in 11.34s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.62it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 72.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 15: train loss 1.5545, test loss 1.3307, accuracy 5337/10000 in 11.54s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.00it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 73.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 16: train loss 1.5551, test loss 1.3463, accuracy 5409/10000 in 11.83s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.99it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 76.30it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 17: train loss 1.5352, test loss 1.3289, accuracy 5437/10000 in 11.64s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.17it/s]\n",
            "  1%|          | 7/782 [00:00<00:12, 64.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 18: train loss 1.5381, test loss 1.3338, accuracy 5352/10000 in 11.36s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 75.31it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 19: train loss 1.5311, test loss 1.3088, accuracy 5489/10000 in 11.85s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.75it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 20: train loss 1.5289, test loss 1.3119, accuracy 5459/10000 in 11.39s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.45it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 21: train loss 1.5192, test loss 1.2950, accuracy 5571/10000 in 11.46s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.36it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 22: train loss 1.5242, test loss 1.2995, accuracy 5499/10000 in 11.48s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.89it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 23: train loss 1.5155, test loss 1.2938, accuracy 5599/10000 in 11.32s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.00it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 24: train loss 1.5097, test loss 1.2939, accuracy 5523/10000 in 11.37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 73.65it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 25: train loss 1.5009, test loss 1.2907, accuracy 5525/10000 in 12.07s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.63it/s]\n",
            "  1%|          | 7/782 [00:00<00:12, 63.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 26: train loss 1.5020, test loss 1.2845, accuracy 5609/10000 in 11.49s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 74.79it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 72.94it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 27: train loss 1.4933, test loss 1.2742, accuracy 5641/10000 in 11.93s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.25it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 28: train loss 1.4967, test loss 1.2796, accuracy 5583/10000 in 11.58s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.23it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 29: train loss 1.4880, test loss 1.2805, accuracy 5700/10000 in 11.59s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.14it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 74.00it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 30: train loss 1.4812, test loss 1.2367, accuracy 5757/10000 in 11.47s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.19it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 31: train loss 1.4891, test loss 1.2586, accuracy 5648/10000 in 11.49s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.20it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 32: train loss 1.4858, test loss 1.2723, accuracy 5584/10000 in 11.84s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 74.57it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 33: train loss 1.4731, test loss 1.2514, accuracy 5725/10000 in 11.98s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.61it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 34: train loss 1.4764, test loss 1.2729, accuracy 5765/10000 in 11.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 75.92it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 35: train loss 1.4606, test loss 1.2519, accuracy 5755/10000 in 11.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.81it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 36: train loss 1.4640, test loss 1.2352, accuracy 5820/10000 in 11.26s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.59it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 81.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 37: train loss 1.4711, test loss 1.2235, accuracy 5779/10000 in 11.55s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.15it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 38: train loss 1.4510, test loss 1.2238, accuracy 5780/10000 in 11.47s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.02it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 81.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 39: train loss 1.4588, test loss 1.2213, accuracy 5872/10000 in 11.35s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.28it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 71.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 40: train loss 1.4567, test loss 1.2324, accuracy 5788/10000 in 11.74s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 78.02it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 78.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 41: train loss 1.4502, test loss 1.2370, accuracy 5728/10000 in 11.51s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.36it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 76.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 42: train loss 1.4514, test loss 1.1933, accuracy 5909/10000 in 11.31s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.06it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 43: train loss 1.4440, test loss 1.2293, accuracy 5890/10000 in 11.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 79.46it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 80.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 44: train loss 1.4462, test loss 1.2149, accuracy 5865/10000 in 11.30s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.20it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 81.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 45: train loss 1.4481, test loss 1.2120, accuracy 5894/10000 in 11.72s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.46it/s]\n",
            "  1%|          | 8/782 [00:00<00:09, 79.71it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 46: train loss 1.4446, test loss 1.2138, accuracy 5854/10000 in 11.68s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 76.98it/s]\n",
            "  1%|          | 9/782 [00:00<00:09, 81.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 47: train loss 1.4439, test loss 1.1978, accuracy 5919/10000 in 11.61s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 77.00it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 72.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 48: train loss 1.4389, test loss 1.2077, accuracy 5914/10000 in 11.70s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:09<00:00, 78.56it/s]\n",
            "  1%|          | 8/782 [00:00<00:10, 74.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 49: train loss 1.4449, test loss 1.1982, accuracy 5958/10000 in 11.50s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:10<00:00, 75.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 50: train loss 1.4356, test loss 1.2071, accuracy 5910/10000 in 11.86s\n"
          ]
        }
      ],
      "source": [
        "perfs = []\n",
        "for epoch in range(1, N_EPOCHS + 1):\n",
        "    t0 = time.time()\n",
        "    train_loss = train(epoch, verbose=False)\n",
        "    test_loss, correct = test(verbose=False)\n",
        "    perfs.append([epoch, train_loss, test_loss, correct, len(test_loader.dataset), time.time() - t0])\n",
        "    print(\"epoch {}: train loss {:.4f}, test loss {:.4f}, accuracy {}/{} in {:.2f}s\".format(*perfs[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>test_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>n_test</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.169914</td>\n",
              "      <td>1.752367</td>\n",
              "      <td>3675</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.012165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.840080</td>\n",
              "      <td>1.620591</td>\n",
              "      <td>4170</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.397995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.763046</td>\n",
              "      <td>1.570013</td>\n",
              "      <td>4266</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.570542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.724817</td>\n",
              "      <td>1.517299</td>\n",
              "      <td>4500</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.876798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.685609</td>\n",
              "      <td>1.503470</td>\n",
              "      <td>4717</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.277871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1.662315</td>\n",
              "      <td>1.483279</td>\n",
              "      <td>4761</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.765396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>1.640964</td>\n",
              "      <td>1.447362</td>\n",
              "      <td>4833</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.396923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>1.624725</td>\n",
              "      <td>1.442763</td>\n",
              "      <td>4869</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.572115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1.613046</td>\n",
              "      <td>1.393994</td>\n",
              "      <td>4994</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.684517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1.603802</td>\n",
              "      <td>1.380717</td>\n",
              "      <td>5107</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.619156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1.597191</td>\n",
              "      <td>1.378265</td>\n",
              "      <td>5171</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.558745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1.581511</td>\n",
              "      <td>1.371412</td>\n",
              "      <td>5168</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.544060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1.570523</td>\n",
              "      <td>1.346479</td>\n",
              "      <td>5320</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.859860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>1.562144</td>\n",
              "      <td>1.351548</td>\n",
              "      <td>5294</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.335763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1.554499</td>\n",
              "      <td>1.330698</td>\n",
              "      <td>5337</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.541710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1.555082</td>\n",
              "      <td>1.346293</td>\n",
              "      <td>5409</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.833996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>1.535244</td>\n",
              "      <td>1.328871</td>\n",
              "      <td>5437</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.638510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1.538110</td>\n",
              "      <td>1.333755</td>\n",
              "      <td>5352</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.361728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>1.531073</td>\n",
              "      <td>1.308771</td>\n",
              "      <td>5489</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.847419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1.528905</td>\n",
              "      <td>1.311850</td>\n",
              "      <td>5459</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.391759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>1.519237</td>\n",
              "      <td>1.294963</td>\n",
              "      <td>5571</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.456195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1.524166</td>\n",
              "      <td>1.299526</td>\n",
              "      <td>5499</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.482363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1.515454</td>\n",
              "      <td>1.293815</td>\n",
              "      <td>5599</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.319931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1.509727</td>\n",
              "      <td>1.293865</td>\n",
              "      <td>5523</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.369551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>1.500931</td>\n",
              "      <td>1.290735</td>\n",
              "      <td>5525</td>\n",
              "      <td>10000</td>\n",
              "      <td>12.065733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>1.501995</td>\n",
              "      <td>1.284510</td>\n",
              "      <td>5609</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.489279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>1.493296</td>\n",
              "      <td>1.274153</td>\n",
              "      <td>5641</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.933470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>1.496725</td>\n",
              "      <td>1.279568</td>\n",
              "      <td>5583</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.576827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1.487993</td>\n",
              "      <td>1.280478</td>\n",
              "      <td>5700</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.587391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>1.481239</td>\n",
              "      <td>1.236744</td>\n",
              "      <td>5757</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.469432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "      <td>1.489067</td>\n",
              "      <td>1.258646</td>\n",
              "      <td>5648</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.486207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>32</td>\n",
              "      <td>1.485838</td>\n",
              "      <td>1.272255</td>\n",
              "      <td>5584</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.843412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>33</td>\n",
              "      <td>1.473095</td>\n",
              "      <td>1.251402</td>\n",
              "      <td>5725</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.977185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>34</td>\n",
              "      <td>1.476354</td>\n",
              "      <td>1.272901</td>\n",
              "      <td>5765</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.623793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>35</td>\n",
              "      <td>1.460555</td>\n",
              "      <td>1.251890</td>\n",
              "      <td>5755</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.768436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>36</td>\n",
              "      <td>1.463994</td>\n",
              "      <td>1.235249</td>\n",
              "      <td>5820</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.258665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>37</td>\n",
              "      <td>1.471099</td>\n",
              "      <td>1.223512</td>\n",
              "      <td>5779</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.546394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>38</td>\n",
              "      <td>1.450969</td>\n",
              "      <td>1.223793</td>\n",
              "      <td>5780</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.473965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>1.458825</td>\n",
              "      <td>1.221349</td>\n",
              "      <td>5872</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.347558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>40</td>\n",
              "      <td>1.456747</td>\n",
              "      <td>1.232436</td>\n",
              "      <td>5788</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.742687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>41</td>\n",
              "      <td>1.450242</td>\n",
              "      <td>1.237012</td>\n",
              "      <td>5728</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.507917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>42</td>\n",
              "      <td>1.451354</td>\n",
              "      <td>1.193295</td>\n",
              "      <td>5909</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.306072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>43</td>\n",
              "      <td>1.444023</td>\n",
              "      <td>1.229257</td>\n",
              "      <td>5890</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.767976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>44</td>\n",
              "      <td>1.446178</td>\n",
              "      <td>1.214856</td>\n",
              "      <td>5865</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.298105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>45</td>\n",
              "      <td>1.448117</td>\n",
              "      <td>1.211978</td>\n",
              "      <td>5894</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.719686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>46</td>\n",
              "      <td>1.444610</td>\n",
              "      <td>1.213834</td>\n",
              "      <td>5854</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.684426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>47</td>\n",
              "      <td>1.443885</td>\n",
              "      <td>1.197752</td>\n",
              "      <td>5919</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.606272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>48</td>\n",
              "      <td>1.438910</td>\n",
              "      <td>1.207737</td>\n",
              "      <td>5914</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.698304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>1.444946</td>\n",
              "      <td>1.198205</td>\n",
              "      <td>5958</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.495326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>1.435570</td>\n",
              "      <td>1.207149</td>\n",
              "      <td>5910</td>\n",
              "      <td>10000</td>\n",
              "      <td>11.858316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    epoch  train_loss  test_loss  accuracy  n_test       time\n",
              "0       1    2.169914   1.752367      3675   10000  12.012165\n",
              "1       2    1.840080   1.620591      4170   10000  11.397995\n",
              "2       3    1.763046   1.570013      4266   10000  11.570542\n",
              "3       4    1.724817   1.517299      4500   10000  11.876798\n",
              "4       5    1.685609   1.503470      4717   10000  11.277871\n",
              "5       6    1.662315   1.483279      4761   10000  11.765396\n",
              "6       7    1.640964   1.447362      4833   10000  11.396923\n",
              "7       8    1.624725   1.442763      4869   10000  11.572115\n",
              "8       9    1.613046   1.393994      4994   10000  11.684517\n",
              "9      10    1.603802   1.380717      5107   10000  11.619156\n",
              "10     11    1.597191   1.378265      5171   10000  11.558745\n",
              "11     12    1.581511   1.371412      5168   10000  11.544060\n",
              "12     13    1.570523   1.346479      5320   10000  11.859860\n",
              "13     14    1.562144   1.351548      5294   10000  11.335763\n",
              "14     15    1.554499   1.330698      5337   10000  11.541710\n",
              "15     16    1.555082   1.346293      5409   10000  11.833996\n",
              "16     17    1.535244   1.328871      5437   10000  11.638510\n",
              "17     18    1.538110   1.333755      5352   10000  11.361728\n",
              "18     19    1.531073   1.308771      5489   10000  11.847419\n",
              "19     20    1.528905   1.311850      5459   10000  11.391759\n",
              "20     21    1.519237   1.294963      5571   10000  11.456195\n",
              "21     22    1.524166   1.299526      5499   10000  11.482363\n",
              "22     23    1.515454   1.293815      5599   10000  11.319931\n",
              "23     24    1.509727   1.293865      5523   10000  11.369551\n",
              "24     25    1.500931   1.290735      5525   10000  12.065733\n",
              "25     26    1.501995   1.284510      5609   10000  11.489279\n",
              "26     27    1.493296   1.274153      5641   10000  11.933470\n",
              "27     28    1.496725   1.279568      5583   10000  11.576827\n",
              "28     29    1.487993   1.280478      5700   10000  11.587391\n",
              "29     30    1.481239   1.236744      5757   10000  11.469432\n",
              "30     31    1.489067   1.258646      5648   10000  11.486207\n",
              "31     32    1.485838   1.272255      5584   10000  11.843412\n",
              "32     33    1.473095   1.251402      5725   10000  11.977185\n",
              "33     34    1.476354   1.272901      5765   10000  11.623793\n",
              "34     35    1.460555   1.251890      5755   10000  11.768436\n",
              "35     36    1.463994   1.235249      5820   10000  11.258665\n",
              "36     37    1.471099   1.223512      5779   10000  11.546394\n",
              "37     38    1.450969   1.223793      5780   10000  11.473965\n",
              "38     39    1.458825   1.221349      5872   10000  11.347558\n",
              "39     40    1.456747   1.232436      5788   10000  11.742687\n",
              "40     41    1.450242   1.237012      5728   10000  11.507917\n",
              "41     42    1.451354   1.193295      5909   10000  11.306072\n",
              "42     43    1.444023   1.229257      5890   10000  11.767976\n",
              "43     44    1.446178   1.214856      5865   10000  11.298105\n",
              "44     45    1.448117   1.211978      5894   10000  11.719686\n",
              "45     46    1.444610   1.213834      5854   10000  11.684426\n",
              "46     47    1.443885   1.197752      5919   10000  11.606272\n",
              "47     48    1.438910   1.207737      5914   10000  11.698304\n",
              "48     49    1.444946   1.198205      5958   10000  11.495326\n",
              "49     50    1.435570   1.207149      5910   10000  11.858316"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_perfs = pd.DataFrame(perfs, columns=[\"epoch\", \"train_loss\", \"test_loss\", \"accuracy\", \"n_test\", \"time\"])\n",
        "df_perfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAFkCAYAAABW9YMrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQAkSSqQAUCSpAIZACRJKtD/Ad3ajXLgimUrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f33281b00b8>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_perfs[[\"train_loss\", \"test_loss\"]].plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}