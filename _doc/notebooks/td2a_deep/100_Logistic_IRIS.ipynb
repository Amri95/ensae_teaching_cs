{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 100 - Logistic Regression with IRIS and pytorch\n",
        "\n",
        "First steps with [pytorch](http://pytorch.org/) and [Iris](http://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Note:** install [tqdm](https://pypi.python.org/pypi/tqdm) if not installed: ``!pip install tqdm``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch 0.2.0_4\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "print(\"torch\", torch.__version__)\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, Y = load_iris(return_X_y=True)\n",
        "X = X.astype(\"float32\")\n",
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((112, 4), (112,), (38, 4), (38,))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ftrain = np.arange(X.shape[0]) % 4 != 0\n",
        "Xtrain, Ytrain = X[ftrain, :], Y[ftrain]\n",
        "Xtest, Ytest = X[~ftrain, :], Y[~ftrain]\n",
        "Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "N_EPOCHS = 2000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Net()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loss_fn = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "Xtrain_ = Variable(torch.from_numpy(Xtrain))\n",
        "Xtest_ = Variable(torch.from_numpy(Xtest))\n",
        "Ytrain_ = Variable(torch.from_numpy(Ytrain))\n",
        "Ytest_ = Variable(torch.from_numpy(Ytest))\n",
        "perfs = []\n",
        "for t in range(1, N_EPOCHS + 1):\n",
        "    # Before the backward pass, use the optimizer object to zero all of the\n",
        "    # gradients for the variables it will update (which are the learnable weights\n",
        "    # of the model)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass: compute predicted y by passing x to the model.\n",
        "    Ypred = model(Xtrain_)\n",
        "\n",
        "    # Compute and print loss.\n",
        "    loss = loss_fn(Ypred , Ytrain_)\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model\n",
        "    # parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Calling the step function on an Optimizer makes an update to its\n",
        "    # parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    Ypred_test = model(Xtest_)\n",
        "    loss_test = loss_fn(Ypred_test, Ytest_)\n",
        "    pred = Ypred_test.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    accuracy = pred.eq(Ytest_.data.view_as(pred)).cpu().sum() / Ytest.size\n",
        "    perfs.append([t, loss.data[0], loss_test.data[0], accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last accuracy 0.921\n"
          ]
        }
      ],
      "source": [
        "df_perfs = pd.DataFrame(perfs, columns=[\"epoch\", \"train_loss\", \"test_loss\", \"accuracy\"]).set_index(\"epoch\")\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "print(\"Last accuracy %.3f\" % df_perfs.accuracy.iloc[-1])\n",
        "df_perfs[[\"train_loss\", \"test_loss\"]].plot(ax=ax1);\n",
        "df_perfs[[\"accuracy\"]].plot(ax=ax2);\n",
        "plt.ylim(ymin=0.7);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}