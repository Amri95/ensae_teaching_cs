{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# API de scikit-learn\n",
        "\n",
        "Pr\u00e9sentation de l'API de *scikit-learn* et impl\u00e9mentation d'un pr\u00e9dicteur fait maison. On utilise le jeu du Titanic qu'on peut r\u00e9cup\u00e9rer sur [opendatasoft](https://public.opendatasoft.com/explore/dataset/titanic-passengers/?flg=fr) ou [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets/tree/master/Datasets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "\n",
              "   Parch     Ticket     Fare Cabin Embarked  \n",
              "0      0  A/5 21171   7.2500   NaN        S  \n",
              "1      0   PC 17599  71.2833   C85        C  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "df = pandas.read_csv(\"titanic.csv/titanic.csv\")\n",
        "df.head(n=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = df[[\"Age\", \"Fare\"]], df['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input contains NaN, infinity or a value too large for dtype('float64').\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "cls = LogisticRegression()\n",
        "try:\n",
        "    cls.fit(X_train, y_train)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Imputer\n",
        "imp = Imputer()\n",
        "imp.fit(X_train)\n",
        "X_train_nomiss = imp.transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls = LogisticRegression()\n",
        "cls.fit(X_train_nomiss, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6681614349775785"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cls.score(imp.transform(X_test), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False))])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "pipe = make_pipeline(Imputer(), LogisticRegression())\n",
        "pipe.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6681614349775785"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score='raise',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('logisticregression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
              "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
              "          verbose=0, warm_start=False))]),\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'imputer__strategy': ['mean', 'most_frequent'], 'logisticregression__max_iter': [5, 10, 50]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=0)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(pipe, {\"imputer__strategy\": ['mean', 'most_frequent'],\n",
        "                           \"logisticregression__max_iter\": [5, 10, 50]})\n",
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>param_imputer__strategy</th>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>most_frequent</td>\n",
              "      <td>most_frequent</td>\n",
              "      <td>most_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_logisticregression__max_iter</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split0_test_score</th>\n",
              "      <td>0.659193</td>\n",
              "      <td>0.659193</td>\n",
              "      <td>0.659193</td>\n",
              "      <td>0.668161</td>\n",
              "      <td>0.668161</td>\n",
              "      <td>0.668161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split1_test_score</th>\n",
              "      <td>0.681614</td>\n",
              "      <td>0.681614</td>\n",
              "      <td>0.681614</td>\n",
              "      <td>0.681614</td>\n",
              "      <td>0.681614</td>\n",
              "      <td>0.681614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split2_test_score</th>\n",
              "      <td>0.612613</td>\n",
              "      <td>0.626126</td>\n",
              "      <td>0.626126</td>\n",
              "      <td>0.612613</td>\n",
              "      <td>0.630631</td>\n",
              "      <td>0.630631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_score</th>\n",
              "      <td>0.651198</td>\n",
              "      <td>0.655689</td>\n",
              "      <td>0.655689</td>\n",
              "      <td>0.654192</td>\n",
              "      <td>0.66018</td>\n",
              "      <td>0.66018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_test_score</th>\n",
              "      <td>0.0287224</td>\n",
              "      <td>0.0227799</td>\n",
              "      <td>0.0227799</td>\n",
              "      <td>0.0298453</td>\n",
              "      <td>0.0215598</td>\n",
              "      <td>0.0215598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            0          1          2  \\\n",
              "param_imputer__strategy                  mean       mean       mean   \n",
              "param_logisticregression__max_iter          5         10         50   \n",
              "split0_test_score                    0.659193   0.659193   0.659193   \n",
              "split1_test_score                    0.681614   0.681614   0.681614   \n",
              "split2_test_score                    0.612613   0.626126   0.626126   \n",
              "mean_test_score                      0.651198   0.655689   0.655689   \n",
              "std_test_score                      0.0287224  0.0227799  0.0227799   \n",
              "rank_test_score                             6          3          3   \n",
              "\n",
              "                                                3              4  \\\n",
              "param_imputer__strategy             most_frequent  most_frequent   \n",
              "param_logisticregression__max_iter              5             10   \n",
              "split0_test_score                        0.668161       0.668161   \n",
              "split1_test_score                        0.681614       0.681614   \n",
              "split2_test_score                        0.612613       0.630631   \n",
              "mean_test_score                          0.654192        0.66018   \n",
              "std_test_score                          0.0298453      0.0215598   \n",
              "rank_test_score                                 5              1   \n",
              "\n",
              "                                                5  \n",
              "param_imputer__strategy             most_frequent  \n",
              "param_logisticregression__max_iter             50  \n",
              "split0_test_score                        0.668161  \n",
              "split1_test_score                        0.681614  \n",
              "split2_test_score                        0.630631  \n",
              "mean_test_score                           0.66018  \n",
              "std_test_score                          0.0215598  \n",
              "rank_test_score                                 1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = pandas.DataFrame(grid.cv_results_)\n",
        "col = [_ for _ in res.columns if 'param_' in _ or \"test_score\" in _]\n",
        "res[col].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy\n",
        "\n",
        "class MeanPredictor(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, alpha=0.5):\n",
        "        self.alpha = alpha\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        self.mean_ = int(self.alpha + numpy.mean(y))\n",
        "        \n",
        "    def predict(self, X):\n",
        "        return numpy.array(list(self.mean_ for k in range(X.shape[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('meanpredictor', MeanPredictor(alpha=0.5))])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_mean = make_pipeline(Imputer(), MeanPredictor())\n",
        "pipe_mean.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6098654708520179"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe_mean.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score='raise',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('imputer', Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)), ('meanpredictor', MeanPredictor(alpha=0.5))]),\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'imputer__strategy': ['mean', 'most_frequent'], 'meanpredictor__alpha': [0.2, 0.5, 0.8]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=0)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid = GridSearchCV(pipe_mean, {\"imputer__strategy\": ['mean', 'most_frequent'],\n",
        "                                \"meanpredictor__alpha\": [0.2, 0.5, 0.8]})\n",
        "grid.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n",
            "c:\\python370_x64\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
            "  warnings.warn(*warn_args, **warn_kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>param_imputer__strategy</th>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>mean</td>\n",
              "      <td>most_frequent</td>\n",
              "      <td>most_frequent</td>\n",
              "      <td>most_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>param_meanpredictor__alpha</th>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split0_test_score</th>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.381166</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.381166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split1_test_score</th>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.381166</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.618834</td>\n",
              "      <td>0.381166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>split2_test_score</th>\n",
              "      <td>0.617117</td>\n",
              "      <td>0.617117</td>\n",
              "      <td>0.382883</td>\n",
              "      <td>0.617117</td>\n",
              "      <td>0.617117</td>\n",
              "      <td>0.382883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean_test_score</th>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.381737</td>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.381737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std_test_score</th>\n",
              "      <td>0.000808777</td>\n",
              "      <td>0.000808777</td>\n",
              "      <td>0.000808777</td>\n",
              "      <td>0.000808777</td>\n",
              "      <td>0.000808777</td>\n",
              "      <td>0.000808777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rank_test_score</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      0            1            2  \\\n",
              "param_imputer__strategy            mean         mean         mean   \n",
              "param_meanpredictor__alpha          0.2          0.5          0.8   \n",
              "split0_test_score              0.618834     0.618834     0.381166   \n",
              "split1_test_score              0.618834     0.618834     0.381166   \n",
              "split2_test_score              0.617117     0.617117     0.382883   \n",
              "mean_test_score                0.618263     0.618263     0.381737   \n",
              "std_test_score              0.000808777  0.000808777  0.000808777   \n",
              "rank_test_score                       1            1            5   \n",
              "\n",
              "                                        3              4              5  \n",
              "param_imputer__strategy     most_frequent  most_frequent  most_frequent  \n",
              "param_meanpredictor__alpha            0.2            0.5            0.8  \n",
              "split0_test_score                0.618834       0.618834       0.381166  \n",
              "split1_test_score                0.618834       0.618834       0.381166  \n",
              "split2_test_score                0.617117       0.617117       0.382883  \n",
              "mean_test_score                  0.618263       0.618263       0.381737  \n",
              "std_test_score                0.000808777    0.000808777    0.000808777  \n",
              "rank_test_score                         1              1              5  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res = pandas.DataFrame(grid.cv_results_)\n",
        "col = [_ for _ in res.columns if 'param_' in _ or \"test_score\" in _]\n",
        "res[col].T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "best = grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(\"model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"model.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X_test) == best.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}