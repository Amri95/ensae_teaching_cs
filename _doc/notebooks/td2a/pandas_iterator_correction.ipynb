{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas et itérateurs - correction\n",
    "\n",
    "[pandas](http://pandas.pydata.org/) a tendance a prendre beaucoup d'espace mémoire pour charger les données, environ trois fois plus que sa taille sur disque.  Quand la mémoire n'est pas assez grande, que peut-on faire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "import pandas\n",
    "df = pandas.DataFrame(data.data)\n",
    "df.column = \"X1 X2 X3 X4\".split()\n",
    "df[\"target\"] = data.target\n",
    "df.to_csv(\"iris.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : itérer sur un grand fichier\n",
    "\n",
    "Le paramètre *iterator* de la fonction [read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) sert à parcourir un fichier par blocs dont la taille est définie par le paramètres *chunksize*. La fonction [read_csv](http://www.xavierdupre.fr/app/pandas_streaming/helpsphinx/pandas_streaming/df/dataframe.html#pandas_streaming.df.dataframe.StreamingDataFrame.read_csv) implémente ce mécanisme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 5)\n",
      "(60, 5)\n",
      "(30, 5)\n"
     ]
    }
   ],
   "source": [
    "for df in pandas.read_csv(\"iris.txt\", sep=\"\\t\", iterator=True, chunksize=60):\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : split train test\n",
    "\n",
    "La solution proposée est implémentée par [train_test_split](http://www.xavierdupre.fr/app/pandas_streaming/helpsphinx/pandas_streaming/df/dataframe.html#pandas_streaming.df.dataframe.StreamingDataFrame.train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_train.txt', 'iris_test.txt']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ce fichier est celui de la compétition 2017\n",
    "# -> Il doit être téléchargé puis soit déplacé dans le répertoire courant, soit indiqué par son chemmin absolu\n",
    "# L'approche suivante par itérateur évite de charger les 179k lignes en mémoire\n",
    "# -> Vous pourrez constater que Python utilise moins de mémoire que la taille du fichier\n",
    "df_full_it = pd.read_csv('off_train_all.txt',\n",
    "                         sep='\\t',\n",
    "                         chunksize=1000,\n",
    "                         encoding='utf-8',\n",
    "                         engine='python')\n",
    "\n",
    "first_exec = True\n",
    "\n",
    "for df_full_chunk in df_full_it:\n",
    "    X_train_chunk, X_test_chunk = train_test_split(df_full_chunk)\n",
    "    if first_exec:\n",
    "        X_train_chunk.to_csv(\"X_train.csv\", sep=\"\\t\", index=False)\n",
    "        X_test_chunk.to_csv(\"X_test.csv\", sep=\"\\t\", index=False)\n",
    "        first_exec = False\n",
    "    else:\n",
    "        X_train_chunk.to_csv(\"X_train.csv\", sep=\"\\t\", index=False, mode='a', header=False)\n",
    "        X_test_chunk.to_csv(\"X_test.csv\", sep=\"\\t\", index=False, mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : stratify ?\n",
    "\n",
    "Le paramètre *stratify* est intéressant pour un problème de classification et quand une classes et sous-représentée. Il est fort probable  que cette classe ne soit pas assez représentée dans l'un des deux jeux et c'est pourquoi il existe une option pour imposer un nombre d'exemples de cette dans chaque des deux jeux (train, test). La qualité des modèles est accrue tout comme la qualité des sondages sur un [échantillonnage stratifié](https://en.wikipedia.org/wiki/Stratified_sampling).\n",
    "\n",
    "Si jamais tout ces exemples sont placés au début du gros fichier à lire, le programme commence à avoir une fausse idée de la répartition des classes. La seule façon de faire est de faire d'abord une division train/test par classe (indiqué par la variable de stratification) puis de recomposer les bases d'apprentissage et de tests en imposant les proportions voulues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "strat_name = 'hasE'\n",
    "\n",
    "df_full_it = pd.read_csv('off_train_all.txt',\n",
    "                         sep='\\t',\n",
    "                         chunksize=1000,\n",
    "                         encoding='utf-8',\n",
    "                         dtype=object,\n",
    "                         engine='python')\n",
    "\n",
    "strat_list = []\n",
    "\n",
    "for df_full_chunk in df_full_it:\n",
    "    for current_strat in df_full_chunk[strat_name].unique():\n",
    "        if str(current_strat) in strat_list:\n",
    "            df_full_chunk[df_full_chunk[strat_name] == current_strat].to_csv(\"strat_{}.csv\".format(current_strat),\n",
    "                                                                             sep=\"\\t\",\n",
    "                                                                             index=False,\n",
    "                                                                             encoding='utf-8',\n",
    "                                                                             mode='a',\n",
    "                                                                             header=False)\n",
    "        else:\n",
    "            strat_list.append(str(current_strat))\n",
    "            df_full_chunk[df_full_chunk[strat_name] == current_strat].to_csv(\"strat_{}.csv\".format(current_strat),\n",
    "                                                                             sep=\"\\t\",\n",
    "                                                                             index=False,\n",
    "                                                                             encoding='utf-8')\n",
    "\n",
    "first_exec = True\n",
    "\n",
    "for current_strat in strat_list:\n",
    "    df_strat_it = pd.read_csv(\"strat_{}.csv\".format(current_strat),\n",
    "                              sep='\\t',\n",
    "                              chunksize=1000,\n",
    "                              encoding='utf-8',\n",
    "                              dtype=object,\n",
    "                              engine='python')\n",
    "    for df_strat_chunk in df_strat_it:\n",
    "        X_train_chunk, X_test_chunk = train_test_split(df_strat_chunk)\n",
    "        if first_exec:\n",
    "            X_train_chunk.to_csv(\"X_train.csv\", sep=\"\\t\", index=False, encoding='utf-8')\n",
    "            X_test_chunk.to_csv(\"X_test.csv\", sep=\"\\t\", index=False, encoding='utf-8')\n",
    "            first_exec = False\n",
    "        else:\n",
    "            X_train_chunk.to_csv(\"X_train.csv\", sep=\"\\t\", index=False, encoding='utf-8', mode='a', header=False)\n",
    "            X_test_chunk.to_csv(\"X_test.csv\", sep=\"\\t\", index=False, encoding='utf-8', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 : quelques idées pour un group by ?\n",
    "\n",
    "La fonction [groupby](http://www.xavierdupre.fr/app/pandas_streaming/helpsphinx/pandas_streaming/df/dataframe.html#pandas_streaming.df.dataframe.StreamingDataFrame.groupby) implémente une façon de faire. Il faut distinguer deux cas possibles. Premier cas, l'agrégation aboutit à un résultat qui tient en mémoire auquel on peut s'en sortir aisément. Dans le second cas, l'agrégation ne tient pas en mémoire et il faudra probablement passer par un fichier intermédiaire..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
